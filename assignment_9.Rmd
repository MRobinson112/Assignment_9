---
title: "assignment 9"
author: "Michael Robinson"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
library(httr)
library(jsonlite)
library(dplyr)
library(tidytext)
library(ggplot2)
library(tidyr)
library(stringr)



# Function to Get articles from NYT Article Search API

Get_NYT_Articles <- function(api_key, query, page = 0) {
  base_url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json"
  response <- GET(url = base_url,
                  query = list(q = query,
                               page = page,
                               'api-key' = api_key))
  
  # Check if the request was successful
  if (status_code(response) == 200) {
    content <- content(response, "text")
    json <- fromJSON(content, flatten = TRUE)
    
    # Check for articles in the response
    if (length(json$response$docs) > 0) {
      articles <- json$response$docs
      df <- as.data.frame(articles)
      return(df)
    } else {
      stop("No articles found")
    }
  } else {
    stop("Request failed with status: ", status_code(response))
  }
}

api_key <- 'JMEmmEEIa0QRZMCedK3Ol6QmRHBVNlfE'

# Get articles about "data science"
df_articles <- Get_NYT_Articles(api_key, "CUNY")

# view the head of the DataFrame
glimpse(df_articles)
```

# what are the most used words?

```{r}

df_articles$text <- paste(df_articles$headline.main, df_articles$snippet, df_articles$lead_paragraph, sep = " ")

# Tokenize the text
words <- df_articles %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word) # remove stop words

# Count the words
word_counts <- words %>%
  count(word, sort = TRUE)

# Display the most common words
head(word_counts, n = 10) 

#  visualize the most common words
ggplot(head(word_counts, n = 10), aes(x = reorder(word, n), y = n)) +
  geom_bar(stat = "identity") +
  xlab("Word") +
  ylab("Frequency") +
  coord_flip() + # Flip the axes for horizontal bars
  theme_minimal()

```
